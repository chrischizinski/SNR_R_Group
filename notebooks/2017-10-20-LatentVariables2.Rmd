---
title: "Applied Multivariate:  Latent variable analysis"
output:
  html_notebook: default
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message = FALSE}
library(psych)
library(GGally)
library(ggrepel)
library(gridExtra)
library(polycor)
library(poLCA)
library(tidyverse)

```

# Latent variable analysis

## Factor analysis 

### Exploratory factor analysis (continued)


Load the data

```{r}

goal_scale <- read_csv("https://raw.githubusercontent.com/chrischizinski/SNR_R_Group/master/data/goal_scale.csv")

head(goal_scale)


```


Fit an EFA models with `factanal`

```{r}

agoal.efa<-factanal(~ags1+ags2+ags3+ags4+ags5+ags6+ags7+ags8+ags9+ags10+ags11+ ags12, factors=4, rotation="promax", data = goal_scale )

agoal.efa 

```

#### Loadings

Challenge:  To help interpret our loadings, lets create a visualization of those loadings.  

```{r message = FALSE}
ld<-loadings(agoal.efa)
loadings<-as.data.frame(ld[,])

lt<- data.frame(indicator = paste("ags",1:12, sep =""),
           latent_traits = c("MAP", "MAV", "PAP", "PAV", "MAP","MAV", "MAP", "PAV", "PAP", "PAV", "PAP", "MAV"))

loadings %>% 
  rownames_to_column("indicator") %>% 
  left_join(lt) %>% 
  mutate(indicator = factor(indicator, levels = paste("ags",12:1, sep =""))) %>% 
  gather(factor, value, -indicator, - latent_traits) %>% 
  mutate(value2 = ifelse(abs(value) < 0.1, NA,  value),
         edge_colour = ifelse(is.na(value2), "white", "black"))-> loadings.long 


ggplot(data = loadings.long) +
  geom_point(aes(x = factor, y = indicator, fill = value2, shape = latent_traits, colour = edge_colour), size = 8) +
  scale_colour_manual(values= c("white" = "white", "black" = "black"), guide = FALSE) +
  scale_fill_gradient2(na.value = "white", mid = "blue", high = "red", low = "yellow",limits = c(-1,1.05)) +
  scale_shape_manual(values = c("MAP" = 21, "MAV" = 22, "PAP" = 23, "PAV" = 24)) +
  labs(fill = "Loading", shape = "Latent\ntrait") +
  theme_classic()
```

1.  We see some cross loading by indicators: `ags4`, `ags5`, `ags8`,`ags10`, `ags11`
2. We also see that each factor has multiple latent traits associated with it, suggesting this solution does not conform to the *a priori * 4-factor solution 

#### Variation explained by each factor

While this is printed using `loadings` it is not easily extracted using that function so we need to calculate it ourselves.  The sum of squared loadings (SS_loadings) is taken by multiplying the loadings by itself and then taking the sum of the columns.  The proportional variance is calculated by dividing the SS_loadings by the number of potential factors (i.e., number of rows).  The cumulative variance is calculated by taking the cumulative sum of the proportional variances.  

```{r}
SS_loadings<-colSums(loadings*loadings)
SS_loadings

Prop_var <- SS_loadings / nrow(loadings)
Prop_var

Cuml_var <-cumsum(Prop_var)
Cuml_var
```

#### Relationship among factors

Looking at the output from `factanal()`, we see that generally there is low correlation between factors except 2 and 4.  High correlation (>0.7) between factors is an indication for redundancy among factors

#### Model fit

At the very bottom of the output, we see the chi-square test for goodness of fit.  The chi-square was `r  as.numeric(agoal.efa$STATISTIC)` with `r  as.numeric(agoal.efa$dof)` df and an associated p-value of `r  agoal.efa$PVAL`.  This value is <0.05 leading us to reject the null hypothesis that the model adequately fits the data and suggesting a four-factor model is not appropriate.  However, given chi-square tests sensitivity to sample size and stringent null hypothesis of exact model data fit, this test is probably not sufficiently reliable.  Further, the *a priori* information about the latent traits exist on multiple factors. 

### So how many factors is appropriate?

```{r}
psych::fa.parallel(goal_scale %>% select(ags1:ags12) , fa="fa", fm="ml")
```

So lets look at a 3 factor solution. 

```{r}
agoal.efa3<-factanal(~ags1+ags2+ags3+ags4+ags5+ags6+ags7+ags8+ags9+ags10+ags11+ ags12, factors=3, rotation="promax", data = goal_scale)

agoal.efa3
```


```{r}
loadings3<-as.data.frame(loadings(agoal.efa3)[,])
loadings3%>% 
  rownames_to_column("indicator") %>% 
  left_join(lt) %>% 
  mutate(indicator = factor(indicator, levels = paste("ags",12:1, sep =""))) %>% 
  gather(factor, value, -indicator, - latent_traits) %>% 
  mutate(value2 = ifelse(value < 0.1, NA,  value),
         edge_colour = ifelse(is.na(value2), "white", "black"))-> loadings3.long 

ggplot(data = loadings3.long) +
  geom_point(aes(x = factor, y = indicator, fill = value2, shape = latent_traits, colour = edge_colour), size = 8) +
  scale_colour_manual(values= c("white" = "white", "black" = "black"), guide = FALSE) +
  scale_fill_gradient2(na.value = "white", mid = "blue", high = "red", low = "yellow",limits = c(-1,1.05)) +
  scale_shape_manual(values = c("MAP" = 21, "MAV" = 22, "PAP" = 23, "PAV" = 24)) +
  labs(fill = "Loading", shape = "Latent\ntrait") +
  theme_classic()
```


#### Scores

Factor scores are linear combinations of the observed variables which consider what is shared between the item and the factor (i.e., shared variance) and what is not measured (i.e., the uniqueness or error term variance) 

[source](https://stats.stackexchange.com/questions/126885/methods-to-compute-factor-scores-and-what-is-the-score-coefficient-matrix-in)

Creates a new variable for each factor in the final solution using several methods:

- Regression method maximizes correlation between factor scores and unknown true values of that factor (i.e. maximizes the statistical validity), but the scores are somewhat biased and they somewhat incorrectly correlate between factors (e.g., they correlate even when factors in a solution are orthogonal). These are least-squares estimates.

- PCA's method is also least squares, but with less statistical validity. They are faster to compute; they are not often used in factor analysis nowadays, due to computers. (In PCA, this method is native and optimal.)

- Bartlett's scores are unbiased estimates of true factor values. The scores are computed to correlate accurately with true, unknown values of other factors (e.g. not to correlate with them in orthogonal solution, for example). However, they still may correlate inaccurately with factor scores computed for other factors. These are maximum-likelihood (under multivariate normality of XX assumption) estimates.

- Anderson-Rubin / McDonald-Anderson-Rubin and Green's scores are called correlation preserving because are computed to correlate accurately with factor scores of other factors. Correlations between factor scores equal the correlations between the factors in the solution (so in orthogonal solution, for instance, the scores will be perfectly uncorrelated). But the scores are somewhat biased and their validity may be modest.

To obtain a score using `factanal` you need to specify the scores option. 

```{r}

agoal.efa3<-factanal(~ags1+ags2+ags3+ags4+ags5+ags6+ags7+ags8+ags9+ags10+ags11+ ags12, factors=3, rotation="promax", data = goal_scale, scores = "Bartlett")

efa_scores <- agoal.efa3$scores %>% as.data.frame() %>% rownames_to_column("obs") %>% na.omit()

set.seed(1234)

sub_efa_scores <- efa_scores[sample(25, replace = FALSE),]


a<- ggplot(data = sub_efa_scores) + 
  geom_point(aes(x = Factor1, y = Factor2), colour = "red", alpha = 0.5) +
  geom_text_repel(aes(x = Factor1, y = Factor2, label = obs)) +
  theme_classic()

b<- ggplot(data = sub_efa_scores) + 
  geom_point(aes(x = Factor2, y = Factor3), colour = "red", alpha = 0.5) +
  geom_text_repel(aes(x = Factor2, y = Factor3, label = obs)) +
  theme_classic()

c<- ggplot(data = sub_efa_scores) + 
  geom_point(aes(x = Factor1, y = Factor3), colour = "red", alpha = 0.5) +
  geom_text_repel(aes(x = Factor1, y = Factor3, label = obs)) +
  theme_classic()

grid.arrange(a,b,c, ncol = 3)

```

Factor scores are easy to create but a couple words of caution should be used in using these. 

1.  factor scores are sensitive to the factor extraction method and rotation method used 
2. The problem of “indeterminacy” of the scores, which means that there is not a
unique solution for the factor analysis results and, theoretically, an infinite number of solutions could account for the relationships between the items and factor(s).

There are other solutions that are better if you plan to use "scores" or individual identities

### Fit an EFA models with `psych::fa`

```{r}
agoal.efa.4<-fa(goal_scale %>% select(ags1:ags12) , nfactors=3, residuals=TRUE, rotate="promax",SMC=TRUE, fm="pa")
agoal.efa.4
```

- Root mean square error of approximation (RMSEA):  By convention, values of RMSEA < 0.05 are taken to indicate good model fit,
and values between 0.05 and 0.08 are seen as indicative of adequate model fit and > 0.08 =  poor fit. 

- Tucker–Lewis index (TLI):  a model is considered to exhibit good fit is when the values of CFI and TLI are 0.95 or higher


### Was this all approporiate given our data?

12 questions with results representing a 7-point likert-type scale from 430 college students

In some cases, the measurement scale for data is ordinal, but the variable is treated as continuous. For example, a Likert scale that contains five values - strongly agree, agree, neither agree nor disagree, disagree, and strongly disagree - is ordinal

However, where a Likert scale contains seven or more value - strongly agree, moderately agree, agree, neither agree nor disagree, disagree, moderately disagree, and strongly disagree - the underlying scale is sometimes treated as continuous (although where you should do this is a cause of great dispute).

Lets look at the correlations first as nominal (as we have done above).


```{r fig.width=8}

corr_plot1<-ggcorr(data = NULL,
                    cor_matrix = as.data.frame(agoal.efa3$correlation),
                    palette = "RdGy", 
                   label = TRUE, 
                   label_round = 2,
                   label_size =4, 
                   label_color = "black")

corr_plot1

```

There is a couple ways we can have "categorical" type data.  1st is *nominal* where there are not levels in the data (e.g., `red , green, blue`) and this is created using `factor()`.  2nd is *ordinal* where we do have levels in the data (e.g., (`disagree < neutral < agree`) and this is created using `ordered()`


```{r}
goal_scale  %>% 
  na.omit() %>% 
  mutate_all(ordered) %>% 
  as.data.frame()-> goal_ordered

try(factanal(~ags1+ags2+ags3+ags4+ags5+ags6+ags7+ags8+ags9+ags10+ags11+ ags12, factors=3, rotation="promax", data = goal_ordered))
```

**DOES NOT WORK**

But we do have some options.  We can use the `polycor` package to generate our own polychoric correlation matrices.  **NOTE** You should probably use `ML=TRUE`, but this takes a real long time so for the purposes of this exercise we will not use it.   

```{r warnings = FALSE, fig.width = 10}
pc_goals<-hetcor(goal_ordered)

corr_plot2<-ggcorr(data = NULL,
                    cor_matrix = as.data.frame(pc_goals$correlation),
                    palette = "RdGy", 
                   label = TRUE, 
                   label_round = 2,
                   label_size =4, 
                   label_color = "black")

grid.arrange(corr_plot1 + labs(title = "Nominal") + theme(plot.title = element_text(hjust = 1, size = 22)), 
             corr_plot2 + labs(title = "Ordinal") + theme(plot.title = element_text(hjust = 1, size = 22)),
             ncol = 2)
```

We can see that there tends to be a higher values in the ordinal.

Does this change the factor analysis?


```{r warning = FALSE, echo = TRUE}
agoal.efa.ordered<-fa(r=pc_goals$correlations, 
                      nfactors=3, 
                      residuals=TRUE, rotate="promax",SMC=TRUE, fm="pa")


agoal.efa.ordered
```

Note the "Heywood case was detected." Heywood cases [are] negative estimates of variances or correlation estimates greater than one in absolute value.


## Latent class analysis

Assume the population consists of C different preference groups. An individual’s
preference group is latent. The researcher observes (xi, zi); xi is the set
of individual i’s answers to the attitudinal questions (the individual’s
response pattern), and zi is a vector of observed characteristics of the individual
(covariates) such as gender and retirement status.
The model estimates four types of probabilities: Pr(c:zi), Prðc : zijxiÞ; pqsjc,
and Pr(xi:zi). Pr(c:zi) is the unconditional probability that individual i belongs to group c given his observable characteristics.
Pr(c:zi|xi) is the conditional membership probability. It represents the
probability that individual i belongs to group c as a function of his characteristics
and conditional on his answers to the attitudinal questions.

pqsjc is the probability that an individual in group c answers level s to
attitudinal question q. These response probabilities are the foundation of the
latent-class model and a function of an individual’s preferences; one wants to
estimate the response probabilities and number of preference groups that best
explain the observed response patterns

Pr(xi:zi) is the probability that an individual with characteristics zi has the
response pattern xi

- Latent class analysis is another technique that is used to describe the latent groups in multivariate data
- Used on categorical data (so good for analysis of survey data)
- Similar to partition clustering and factor analysis, we define the number of groups *a priori*
    - models with successively larger numbers of classes are fitted, and the model that has the fewest classes while still accounting for associations among the observed indicator variables is chosen
    - Unlike FA, which groups along a number of axes, LCA groups people into latent classes.
    - FA has both exploratory and confirmatory variants; LCA has no such analogue
- It is assumed that individuals can only be in one class
- Each  latent class is characterized by different probabilities of having each of the characteristics related to the condition of interest. 

### Load the data

We will use the data set `election`. The data consisted of two sets of six questions with four responses each, asking respondents’ opinions of
how well various traits describe presidential candidates Al Gore and George W. Bush. Also potential covariates vote choice, age, education, gender, and party ID. S

```{r}
data(election)
head(election)
```

Lets take a quick look at the data.

Challenge
1. Create a data frame of the counts of people that rated each president among Extremely Well:Not Well at all and NAs for each characteristic
2. Create a histogram that displays those counts for each rating for each characteristic for each president

```{r fig.width = 6}
library(tidyverse)

election %>% 
  select(MORALG:INTELG) %>% 
  gather(type, response, MORALG:INTELG) %>% 
  mutate(president = "Gore") -> gore_data

election %>% 
  select(MORALB:INTELB) %>% 
  gather(type, response, MORALB:INTELB) %>% 
  mutate(president = "Bush") %>% 
  rbind(gore_data) %>% 
  mutate(type = gsub("G", "",type),
         type = gsub("B", "",type)) %>% 
  group_by(president, type,response) %>% 
  summarise(N = n()) %>% 
  ggplot() +
  geom_col(aes(x = response, y = N, fill = type), color = "black") +
  facet_grid(president~type) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "none")

```


If the number of groups fits the data well, the estimated conditional
membership probabilities should be close to 1 or 0; individuals should be
assigned to one of the groups with high probability

```{r}
f.party <- cbind(MORALG, CARESG, KNOWG, LEADG, DISHONG, INTELG, MORALB, CARESB, KNOWB, LEADB, DISHONB, INTELB) ~ PARTY

nes.party <- poLCA(f.party, election, nclass = 3, verbose = FALSE)

names(nes.party)
classes <- 10

fit.stor <- data.frame(matrix(NA, classes,5))

names(fit.stor) <- c("classes", "llik", "aic", "bic", "E")


for(i in 2:classes){
  foo<-poLCA(f.party, election, nclass = i, verbose = FALSE)
  fit.stor$classes[i - 1] <- i
  fit.stor$llik[i - 1] <- foo$llik
  fit.stor$aic[i - 1] <- foo$aic
  fit.stor$bic[i - 1] <- foo$bic
  fit.stor$E[i - 1] <- poLCA.entropy(foo)
  
}

fit.stor
```

